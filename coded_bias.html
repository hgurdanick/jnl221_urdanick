<!-- This is an HTML page for the JNL221 class' first repository.-->

<!DOCTYPE html>
<html>
	<head>
	
		<meta charset="utf-8">
		<title>First repository</title>
		<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,400,300,600,700&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
		<link href='https://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>
	
		<!-- This is where this page's style sheet is defined. -->
		<link type="text/css" rel="stylesheet" href="index.css" />

	</head>
	<body>
	
		<!-- This is the header row for this page. -->
		<div id="intro">
			<h1>Hannah Urdanick</h1>
			<h4>Syracuse University, Fall 2025</h4>
		</div>

		<section>
			<p> A scene that really made the concept of how these algorithms are biased was the scene where 
        they described humans as making robots in their own image—which means making them prejudiced. 
        I knew how data sets worked before, but how they were biased didn’t make sense to me yet. I 
        had a misconception that technology = math, and math can’t be influenced because it is simply 
        math. In fact it is which kind of math you used. This in combination with the information a
        bout women’s sports and women’s colleges being excluded from hiring in Amazon’s resume 
        algorithm helped me realize that these biases aren’t necessarily intentional or malicious. 
        They are a reflection simply of what the world is like.  </p>
      <p><a href="https://guides.library.ttu.edu/pop" target="_blank">Pop culture tends to humanize AI</a>, 
        make it into characters, give it a personality. Media makes algorithms seem intentionally evil 
        or malicious, like they are making racist or sexist decisions (or simply being evil) because 
        that is how they think or what they believe. In reality, these algorithms are simply reflecting 
        the math and information they have been fed. Like the red AI voice said, it’s not the fault of 
        the machine. It’s the fault of the math and the people who created it. I found that interesting.</p>
      <p>Questions:
        1 What led to the incidents that called physical harm to people? What malfunctioned?
        2 Is there a connection between physical harm and the demographics being harmed? (Showing prejudice)

       Hypothesis:
       People underserved/underrepresented in statistics are more likely to face harm from algorithms using these statistics. 
</p>
		</section>

		<div id="end">
			<h4>this page was published on github pages. fonts: montserrat, open sans.</h4>
		</div>


	</body>
</html>
